{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwFeXNaHVSL2"
      },
      "source": [
        "# XLNET TRANSFORMERS MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzfl-dT2YLV2",
        "outputId": "9f67b12b-0cc0-4a2f-97ac-fe670c824d90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (5.0.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 54.5 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 53.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.23.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 5.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f72ozFsVmYz"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB8cuHH3aCJZ",
        "outputId": "d51f5a25-045b-4e57-f11b-b82cf70b1299"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 17.3 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |▋                               | 30 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |▉                               | 40 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█                               | 51 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 92 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██                              | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████                           | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 317 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 327 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 337 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 348 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 358 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 368 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 378 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 389 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 399 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 409 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 419 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 430 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 440 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 450 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 460 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 471 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 481 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 491 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 501 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 512 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 522 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 532 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 542 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 552 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 563 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 573 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 583 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 593 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 604 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 614 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 624 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 634 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 645 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 655 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 665 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 675 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 686 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 696 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 706 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 716 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 727 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 737 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 747 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 757 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 768 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 778 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 788 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 798 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 808 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 819 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 829 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 839 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 849 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 860 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 870 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 880 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 890 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 901 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 911 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 921 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 931 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 942 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 952 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 962 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 972 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 983 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 993 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.3 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.3 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.3 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.3 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.3 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.3 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.3 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.3 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.4 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.4 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.4 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.4 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.4 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.4 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.4 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.4 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.4 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.4 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.5 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.5 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.5 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.5 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.5 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.5 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.5 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.5 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.5 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.5 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.6 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.6 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.6 MB 5.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sxjSSb6aEJL",
        "outputId": "30127b36-4825-4e65-e662-5eaf336db27c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.7.14\n",
            "IPython version      : 7.9.0\n",
            "\n",
            "numpy       : 1.21.6\n",
            "pandas      : 1.3.5\n",
            "torch       : 1.12.1+cu113\n",
            "transformers: 4.23.1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSRtmwRBYLS1"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from transformers import XLNetTokenizer, XLNetModel, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "from pylab import rcParams\n",
        "\n",
        "from torch import nn, optim\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset,RandomSampler,SequentialSampler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "smK00g5tYLQE",
        "outputId": "8dedccd5-29d0-44d8-84f7-b38ce45056aa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-19f67023-0aed-4741-89a0-7319a8c9d9a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Month</th>\n",
              "      <th>Date</th>\n",
              "      <th>Headline_Original</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Headline_Clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>April</td>\n",
              "      <td>Updated: Apr 17, 2020 15:28 IST</td>\n",
              "      <td>Rs 500 notes lay on Delhi street, no one touch...</td>\n",
              "      <td>0</td>\n",
              "      <td>rs note lay delhi street no one touch due coro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>April</td>\n",
              "      <td>Updated: Apr 17, 2020 14:19 IST</td>\n",
              "      <td>Charu Asopa on trolls attacking her over pics ...</td>\n",
              "      <td>0</td>\n",
              "      <td>charu asopa troll attack pics husband keep thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>April</td>\n",
              "      <td>Updated: Apr 17, 2020 13:54 IST</td>\n",
              "      <td>People abandoning their pets are cruel and ign...</td>\n",
              "      <td>0</td>\n",
              "      <td>people abandon pet cruel ignorant richa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>April</td>\n",
              "      <td>Updated: Apr 17, 2020 12:42 IST</td>\n",
              "      <td>Indian women's hockey team to raise funds for ...</td>\n",
              "      <td>0</td>\n",
              "      <td>indian women hockey team raise fund poor affec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>April</td>\n",
              "      <td>Updated: Apr 17, 2020 12:42 IST</td>\n",
              "      <td>Real estate sector faces serious setback due t...</td>\n",
              "      <td>0</td>\n",
              "      <td>real estate sector face serious setback due re...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19f67023-0aed-4741-89a0-7319a8c9d9a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-19f67023-0aed-4741-89a0-7319a8c9d9a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-19f67023-0aed-4741-89a0-7319a8c9d9a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Month                             Date  \\\n",
              "0  April  Updated: Apr 17, 2020 15:28 IST   \n",
              "1  April  Updated: Apr 17, 2020 14:19 IST   \n",
              "2  April  Updated: Apr 17, 2020 13:54 IST   \n",
              "3  April  Updated: Apr 17, 2020 12:42 IST   \n",
              "4  April  Updated: Apr 17, 2020 12:42 IST   \n",
              "\n",
              "                                   Headline_Original  Sentiment  \\\n",
              "0  Rs 500 notes lay on Delhi street, no one touch...          0   \n",
              "1  Charu Asopa on trolls attacking her over pics ...          0   \n",
              "2  People abandoning their pets are cruel and ign...          0   \n",
              "3  Indian women's hockey team to raise funds for ...          0   \n",
              "4  Real estate sector faces serious setback due t...          0   \n",
              "\n",
              "                                      Headline_Clean  \n",
              "0  rs note lay delhi street no one touch due coro...  \n",
              "1  charu asopa troll attack pics husband keep thi...  \n",
              "2            people abandon pet cruel ignorant richa  \n",
              "3  indian women hockey team raise fund poor affec...  \n",
              "4  real estate sector face serious setback due re...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/News_Dataset/Data/Sentiment Analysis/All_Label_Covid_Headlines.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KQ2hkPk5YLNW",
        "outputId": "92fb10df-38a4-4b2b-dc72-36225ccd804e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5f0da78a-566f-4e95-96c5-65057717f37e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Month</th>\n",
              "      <th>Date</th>\n",
              "      <th>Headline_Original</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Headline_Clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5852</th>\n",
              "      <td>June</td>\n",
              "      <td>Updated: Jun 11, 2020 16:15 IST</td>\n",
              "      <td>‘Safe zones' in Pune see rise in cases; PMC re...</td>\n",
              "      <td>1</td>\n",
              "      <td>safe zone pune see rise case pmc ready tackle ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1520</th>\n",
              "      <td>May</td>\n",
              "      <td>Updated: May 13, 2020 12:33 IST</td>\n",
              "      <td>Over 14,500 cases in Mumbai, nearly 5,000 in C...</td>\n",
              "      <td>0</td>\n",
              "      <td>case mumbai nearly chennai list top cities</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5481</th>\n",
              "      <td>April</td>\n",
              "      <td>Updated: Apr 06, 2020 23:22 IST</td>\n",
              "      <td>MPs, experts join forces to form Covid-19 acti...</td>\n",
              "      <td>1</td>\n",
              "      <td>mps experts join force form action group</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1054</th>\n",
              "      <td>May</td>\n",
              "      <td>Updated: May 08, 2020 23:05 IST</td>\n",
              "      <td>Jalandhar Rural police bust gang of drug smugg...</td>\n",
              "      <td>0</td>\n",
              "      <td>jalandhar rural police bust gang drug smuggler...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1318</th>\n",
              "      <td>August</td>\n",
              "      <td>Updated: August 15, 2020  7:48:21 pm</td>\n",
              "      <td>Barcelona's worst defeat in almost 80 years ex...</td>\n",
              "      <td>0</td>\n",
              "      <td>barcelona worst defeat almost years expose pro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6533</th>\n",
              "      <td>August</td>\n",
              "      <td>Updated: August 26, 2020  7:56:22 am</td>\n",
              "      <td>James Anderson gets milestone 600th as England...</td>\n",
              "      <td>1</td>\n",
              "      <td>james anderson get milestone england win test ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9373</th>\n",
              "      <td>November</td>\n",
              "      <td>Published:  23:04 GMT, 3 November 2020</td>\n",
              "      <td>New England's two Republican governors break a...</td>\n",
              "      <td>1</td>\n",
              "      <td>new england two republican governors break awa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1242</th>\n",
              "      <td>August</td>\n",
              "      <td>Updated: August 2, 2020  3:47:48 pm</td>\n",
              "      <td>Bengal: Covid load gets heavier after a grim J...</td>\n",
              "      <td>0</td>\n",
              "      <td>bengal covid load get heavier grim july test t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1430</th>\n",
              "      <td>October</td>\n",
              "      <td>October 9, 2020 2:02:57 pm</td>\n",
              "      <td>Remote teaching professionals in demand as tra...</td>\n",
              "      <td>0</td>\n",
              "      <td>remote teach professionals demand traditional ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10633</th>\n",
              "      <td>October</td>\n",
              "      <td>October 7, 2020 11:22:05 pm</td>\n",
              "      <td>High patient dropout rate in AntiVEGF therapy ...</td>\n",
              "      <td>1</td>\n",
              "      <td>high patient dropout rate antivegf therapy due...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9405</th>\n",
              "      <td>October</td>\n",
              "      <td>Published:  21:21 GMT, 30 October 2020</td>\n",
              "      <td>New York City companies try to lure employees ...</td>\n",
              "      <td>1</td>\n",
              "      <td>new york city company try lure employees back ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5985</th>\n",
              "      <td>April</td>\n",
              "      <td>Updated: Apr 25, 2020 13:33 IST</td>\n",
              "      <td>Lisbon zoo animals feel keepers' love while th...</td>\n",
              "      <td>1</td>\n",
              "      <td>lisbon zoo animals feel keepers love people st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1460</th>\n",
              "      <td>October</td>\n",
              "      <td>October 2, 2020 5:14:16 pm</td>\n",
              "      <td>Gandhi Jayanti: Tripura journalists don black ...</td>\n",
              "      <td>0</td>\n",
              "      <td>gandhi jayanti tripura journalists black ribbo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4793</th>\n",
              "      <td>March</td>\n",
              "      <td>Published:  05:56 BST, 26 March 2020</td>\n",
              "      <td>Trump administration 'ignored' advice of Natio...</td>\n",
              "      <td>0</td>\n",
              "      <td>trump administration advice national security ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1013</th>\n",
              "      <td>May</td>\n",
              "      <td>Updated: May 12, 2020 18:21 IST</td>\n",
              "      <td>A migrant worker desperate to go home, among t...</td>\n",
              "      <td>0</td>\n",
              "      <td>migrant worker desperate go home among two sui...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9333</th>\n",
              "      <td>November</td>\n",
              "      <td>Published:  08:59 GMT, 9 November 2020</td>\n",
              "      <td>Michel Barnier says UK and EU are 'redoubling ...</td>\n",
              "      <td>1</td>\n",
              "      <td>michel barnier say uk eu efforts strike trade ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8000</th>\n",
              "      <td>March</td>\n",
              "      <td>Published:  16:40 GMT, 3 March 2020</td>\n",
              "      <td>'I thought as long as you do not shake hands e...</td>\n",
              "      <td>1</td>\n",
              "      <td>think long not shake hand everything fine twit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4387</th>\n",
              "      <td>September</td>\n",
              "      <td>Published:  23:49 BST, 29 September 2020</td>\n",
              "      <td>Australians are left furious after telcos shut...</td>\n",
              "      <td>0</td>\n",
              "      <td>australians leave furious telcos shut overseas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9627</th>\n",
              "      <td>October</td>\n",
              "      <td>October 12, 2020</td>\n",
              "      <td>Five years on, Israelis see few benefits from ...</td>\n",
              "      <td>1</td>\n",
              "      <td>five years israelis see benefit major gas deal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9884</th>\n",
              "      <td>September</td>\n",
              "      <td>Updated: September 16, 2020  4:46:08 pm</td>\n",
              "      <td>Watch: Zaheer Khan takes fans for a tour of Mu...</td>\n",
              "      <td>1</td>\n",
              "      <td>watch zaheer khan take fan tour mumbai indians...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f0da78a-566f-4e95-96c5-65057717f37e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f0da78a-566f-4e95-96c5-65057717f37e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f0da78a-566f-4e95-96c5-65057717f37e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           Month                                      Date  \\\n",
              "5852        June           Updated: Jun 11, 2020 16:15 IST   \n",
              "1520         May           Updated: May 13, 2020 12:33 IST   \n",
              "5481       April           Updated: Apr 06, 2020 23:22 IST   \n",
              "1054         May           Updated: May 08, 2020 23:05 IST   \n",
              "1318      August      Updated: August 15, 2020  7:48:21 pm   \n",
              "6533      August      Updated: August 26, 2020  7:56:22 am   \n",
              "9373    November    Published:  23:04 GMT, 3 November 2020   \n",
              "1242      August       Updated: August 2, 2020  3:47:48 pm   \n",
              "1430     October                October 9, 2020 2:02:57 pm   \n",
              "10633    October               October 7, 2020 11:22:05 pm   \n",
              "9405     October    Published:  21:21 GMT, 30 October 2020   \n",
              "5985       April           Updated: Apr 25, 2020 13:33 IST   \n",
              "1460     October                October 2, 2020 5:14:16 pm   \n",
              "4793       March      Published:  05:56 BST, 26 March 2020   \n",
              "1013         May           Updated: May 12, 2020 18:21 IST   \n",
              "9333    November    Published:  08:59 GMT, 9 November 2020   \n",
              "8000       March       Published:  16:40 GMT, 3 March 2020   \n",
              "4387   September  Published:  23:49 BST, 29 September 2020   \n",
              "9627     October                          October 12, 2020   \n",
              "9884   September   Updated: September 16, 2020  4:46:08 pm   \n",
              "\n",
              "                                       Headline_Original  Sentiment  \\\n",
              "5852   ‘Safe zones' in Pune see rise in cases; PMC re...          1   \n",
              "1520   Over 14,500 cases in Mumbai, nearly 5,000 in C...          0   \n",
              "5481   MPs, experts join forces to form Covid-19 acti...          1   \n",
              "1054   Jalandhar Rural police bust gang of drug smugg...          0   \n",
              "1318   Barcelona's worst defeat in almost 80 years ex...          0   \n",
              "6533   James Anderson gets milestone 600th as England...          1   \n",
              "9373   New England's two Republican governors break a...          1   \n",
              "1242   Bengal: Covid load gets heavier after a grim J...          0   \n",
              "1430   Remote teaching professionals in demand as tra...          0   \n",
              "10633  High patient dropout rate in AntiVEGF therapy ...          1   \n",
              "9405   New York City companies try to lure employees ...          1   \n",
              "5985   Lisbon zoo animals feel keepers' love while th...          1   \n",
              "1460   Gandhi Jayanti: Tripura journalists don black ...          0   \n",
              "4793   Trump administration 'ignored' advice of Natio...          0   \n",
              "1013   A migrant worker desperate to go home, among t...          0   \n",
              "9333   Michel Barnier says UK and EU are 'redoubling ...          1   \n",
              "8000   'I thought as long as you do not shake hands e...          1   \n",
              "4387   Australians are left furious after telcos shut...          0   \n",
              "9627   Five years on, Israelis see few benefits from ...          1   \n",
              "9884   Watch: Zaheer Khan takes fans for a tour of Mu...          1   \n",
              "\n",
              "                                          Headline_Clean  \n",
              "5852   safe zone pune see rise case pmc ready tackle ...  \n",
              "1520          case mumbai nearly chennai list top cities  \n",
              "5481            mps experts join force form action group  \n",
              "1054   jalandhar rural police bust gang drug smuggler...  \n",
              "1318   barcelona worst defeat almost years expose pro...  \n",
              "6533   james anderson get milestone england win test ...  \n",
              "9373   new england two republican governors break awa...  \n",
              "1242   bengal covid load get heavier grim july test t...  \n",
              "1430   remote teach professionals demand traditional ...  \n",
              "10633  high patient dropout rate antivegf therapy due...  \n",
              "9405   new york city company try lure employees back ...  \n",
              "5985   lisbon zoo animals feel keepers love people st...  \n",
              "1460   gandhi jayanti tripura journalists black ribbo...  \n",
              "4793   trump administration advice national security ...  \n",
              "1013   migrant worker desperate go home among two sui...  \n",
              "9333   michel barnier say uk eu efforts strike trade ...  \n",
              "8000   think long not shake hand everything fine twit...  \n",
              "4387   australians leave furious telcos shut overseas...  \n",
              "9627      five years israelis see benefit major gas deal  \n",
              "9884   watch zaheer khan take fan tour mumbai indians...  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.utils import shuffle\n",
        "df = shuffle(df)\n",
        "df.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kc78A0JXYLIU"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"@[A-Za-z0-9]+\", ' ', text)\n",
        "    text = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', text)\n",
        "    text = re.sub(r\"[^a-zA-z.!?'0-9]\", ' ', text)\n",
        "    text = re.sub('\\t', ' ',  text)\n",
        "    text = re.sub(r\" +\", ' ', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38j_v45nYLDc"
      },
      "outputs": [],
      "source": [
        "df['Headline_Clean'] = df['Headline_Clean'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "KfiPoyIIYK6X",
        "outputId": "5dcb32cb-b82c-4335-fac1-324e36e39a07"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-252bfa54-c820-46d1-81a7-690034a2a2b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Month</th>\n",
              "      <th>Date</th>\n",
              "      <th>Headline_Original</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Headline_Clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5852</th>\n",
              "      <td>June</td>\n",
              "      <td>Updated: Jun 11, 2020 16:15 IST</td>\n",
              "      <td>‘Safe zones' in Pune see rise in cases; PMC re...</td>\n",
              "      <td>1</td>\n",
              "      <td>safe zone pune see rise case pmc ready tackle ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1520</th>\n",
              "      <td>May</td>\n",
              "      <td>Updated: May 13, 2020 12:33 IST</td>\n",
              "      <td>Over 14,500 cases in Mumbai, nearly 5,000 in C...</td>\n",
              "      <td>0</td>\n",
              "      <td>case mumbai nearly chennai list top cities</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5481</th>\n",
              "      <td>April</td>\n",
              "      <td>Updated: Apr 06, 2020 23:22 IST</td>\n",
              "      <td>MPs, experts join forces to form Covid-19 acti...</td>\n",
              "      <td>1</td>\n",
              "      <td>mps experts join force form action group</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1054</th>\n",
              "      <td>May</td>\n",
              "      <td>Updated: May 08, 2020 23:05 IST</td>\n",
              "      <td>Jalandhar Rural police bust gang of drug smugg...</td>\n",
              "      <td>0</td>\n",
              "      <td>jalandhar rural police bust gang drug smuggler...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1318</th>\n",
              "      <td>August</td>\n",
              "      <td>Updated: August 15, 2020  7:48:21 pm</td>\n",
              "      <td>Barcelona's worst defeat in almost 80 years ex...</td>\n",
              "      <td>0</td>\n",
              "      <td>barcelona worst defeat almost years expose pro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6606</th>\n",
              "      <td>September</td>\n",
              "      <td>Updated: September 12, 2020  8:38:53 am</td>\n",
              "      <td>Told to increase ICU beds, some Delhi hospital...</td>\n",
              "      <td>1</td>\n",
              "      <td>told increase icu bed delhi hospitals say full...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1796</th>\n",
              "      <td>April</td>\n",
              "      <td>Apr 9, 2020</td>\n",
              "      <td>Small cinemas in Kansai turn to T-shirts as th...</td>\n",
              "      <td>0</td>\n",
              "      <td>small cinemas kansai turn struggle pandemic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>908</th>\n",
              "      <td>April</td>\n",
              "      <td>Updated: Apr 26, 2020 14:40 IST</td>\n",
              "      <td>Google decodes why remote video calls do not e...</td>\n",
              "      <td>0</td>\n",
              "      <td>google decode remote video call not excite wor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5383</th>\n",
              "      <td>April</td>\n",
              "      <td>Updated: Apr 10, 2020 15:44 IST</td>\n",
              "      <td>Asha Bhonsle, Lata Mangeshkar, KJ Yesudas: Top...</td>\n",
              "      <td>1</td>\n",
              "      <td>asha bhonsle lata mangeshkar kj yesudas top in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3393</th>\n",
              "      <td>May</td>\n",
              "      <td>Published:  13:47 BST, 25 May 2020</td>\n",
              "      <td>Boss of one of Australia's oldest restaurants ...</td>\n",
              "      <td>0</td>\n",
              "      <td>boss one australia oldest restaurants sham gro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10727 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-252bfa54-c820-46d1-81a7-690034a2a2b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-252bfa54-c820-46d1-81a7-690034a2a2b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-252bfa54-c820-46d1-81a7-690034a2a2b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          Month                                     Date  \\\n",
              "5852       June          Updated: Jun 11, 2020 16:15 IST   \n",
              "1520        May          Updated: May 13, 2020 12:33 IST   \n",
              "5481      April          Updated: Apr 06, 2020 23:22 IST   \n",
              "1054        May          Updated: May 08, 2020 23:05 IST   \n",
              "1318     August     Updated: August 15, 2020  7:48:21 pm   \n",
              "...         ...                                      ...   \n",
              "6606  September  Updated: September 12, 2020  8:38:53 am   \n",
              "1796      April                              Apr 9, 2020   \n",
              "908       April          Updated: Apr 26, 2020 14:40 IST   \n",
              "5383      April          Updated: Apr 10, 2020 15:44 IST   \n",
              "3393        May       Published:  13:47 BST, 25 May 2020   \n",
              "\n",
              "                                      Headline_Original  Sentiment  \\\n",
              "5852  ‘Safe zones' in Pune see rise in cases; PMC re...          1   \n",
              "1520  Over 14,500 cases in Mumbai, nearly 5,000 in C...          0   \n",
              "5481  MPs, experts join forces to form Covid-19 acti...          1   \n",
              "1054  Jalandhar Rural police bust gang of drug smugg...          0   \n",
              "1318  Barcelona's worst defeat in almost 80 years ex...          0   \n",
              "...                                                 ...        ...   \n",
              "6606  Told to increase ICU beds, some Delhi hospital...          1   \n",
              "1796  Small cinemas in Kansai turn to T-shirts as th...          0   \n",
              "908   Google decodes why remote video calls do not e...          0   \n",
              "5383  Asha Bhonsle, Lata Mangeshkar, KJ Yesudas: Top...          1   \n",
              "3393  Boss of one of Australia's oldest restaurants ...          0   \n",
              "\n",
              "                                         Headline_Clean  \n",
              "5852  safe zone pune see rise case pmc ready tackle ...  \n",
              "1520         case mumbai nearly chennai list top cities  \n",
              "5481           mps experts join force form action group  \n",
              "1054  jalandhar rural police bust gang drug smuggler...  \n",
              "1318  barcelona worst defeat almost years expose pro...  \n",
              "...                                                 ...  \n",
              "6606  told increase icu bed delhi hospitals say full...  \n",
              "1796        small cinemas kansai turn struggle pandemic  \n",
              "908   google decode remote video call not excite wor...  \n",
              "5383  asha bhonsle lata mangeshkar kj yesudas top in...  \n",
              "3393  boss one australia oldest restaurants sham gro...  \n",
              "\n",
              "[10727 rows x 5 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "PLaKRxhPYK2z",
        "outputId": "bd98146f-ae26-429a-8b11-8367a6e9ede0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "rcParams['figure.figsize'] = 8, 6\n",
        "sns.countplot(df.Sentiment)\n",
        "plt.xlabel('sentiment score');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UHEpK-hYKdZ",
        "outputId": "58f7a8e2-e022-4968-8c9e-610bc8b309fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    5369\n",
              "0    5358\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9Ue3TUFHlvO"
      },
      "outputs": [],
      "source": [
        "class_names = ['positive', 'negative']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "1ef828cb2abd43fc89ffcb243277b0c9",
            "1f9022d899e1450daad7d1047c3c9d0c",
            "0f88590ae31a463e99b66e7a6a3b9004",
            "51ddd0da28af4d8197a05a17a7354c49",
            "ee96eafc4f6841e2a03d743078b142ef",
            "498e7f1f272b42c085897c5878880fe2",
            "a5b08a0f72d4410cba1acaaabf259668",
            "e7cfbe29c29c4ab4a37c7e6326677d9b",
            "382f3c42f7d24d2a9957762904006466",
            "535a649da3724212950244649e5ebb43",
            "cc61149faa204138a74f0b7103d31cc5",
            "52141107a4e8428db8ad8830553c5892",
            "8932532984994115a0850944163156b2",
            "806bade3013b4e1a8e76f0292b33664c",
            "a26924e2feb144bc8e58eec97c67aaec",
            "03803cb4667340e1a685cdcdb69bc917",
            "60c5cfaae4b94d2cb4d586e82afedef1",
            "ee88515d7fa447f1920390f687b728a6",
            "d308fff30bb643ad8dccb83ae101f683",
            "0cc024e4f5f14caebf49c2e11af33f2f",
            "4d0ac8a86e2743c3b168d5c85e7149fd",
            "23e90576e79743fdb905cc420e8538a4"
          ]
        },
        "id": "sK3Zp07OYKZ-",
        "outputId": "5a8e0404-4dd5-45ed-d14f-d632c494865c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ef828cb2abd43fc89ffcb243277b0c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52141107a4e8428db8ad8830553c5892",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/760 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import XLNetTokenizer, XLNetModel\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', model_max_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-DxGr6em8LR"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qlIGROCYKTc"
      },
      "outputs": [],
      "source": [
        "class News(Dataset):\n",
        "\n",
        "    def __init__(self, sentiments, targets, tokenizer, max_len):\n",
        "        self.sentiments = sentiments\n",
        "        self.targets = targets\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.sentiments)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        sentiment = str(self.sentiments[item])\n",
        "        target = self.targets[item]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "        sentiment,\n",
        "        add_special_tokens=True,\n",
        "        truncation=True,\n",
        "        max_length=self.max_len,\n",
        "        return_token_type_ids=False,\n",
        "        pad_to_max_length=False,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        input_ids = pad_sequences(encoding['input_ids'], maxlen=MAX_LEN, dtype=torch.Tensor ,truncating=\"post\",padding=\"post\")\n",
        "        input_ids = input_ids.astype(dtype = 'int64')\n",
        "        input_ids = torch.tensor(input_ids) \n",
        "\n",
        "        attention_mask = pad_sequences(encoding['attention_mask'], maxlen=MAX_LEN, dtype=torch.Tensor ,truncating=\"post\",padding=\"post\")\n",
        "        attention_mask = attention_mask.astype(dtype = 'int64')\n",
        "        attention_mask = torch.tensor(attention_mask)       \n",
        "\n",
        "        return {\n",
        "        'sentiment_text': sentiment,\n",
        "        'input_ids': input_ids,\n",
        "        'attention_mask': attention_mask.flatten(),\n",
        "        'targets': torch.tensor(target, dtype=torch.long)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhUwDIkeYKP_"
      },
      "outputs": [],
      "source": [
        "df_train, df_test = train_test_split(df, test_size=0.3, random_state=0)\n",
        "df_val, df_test = train_test_split(df_test, test_size=0.3, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdddt-cHYKNB",
        "outputId": "4cd0d318-9638-4f62-8c49-602bf2fc3f77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((7508, 5), (2253, 5), (966, 5))"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITTKVifMYKJx"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = News(\n",
        "    sentiments=df.Headline_Clean.to_numpy(),\n",
        "    targets=df.Sentiment.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=2\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZAAPUB3YKGd"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "b8a2ea7acbf442bc8f08ce4a5f6ebf45",
            "fd3fd247b88743a7813e4317e5615149",
            "9d72434520fc45a8b8f0c8a565e33247",
            "967e0b5d37e544a9ba2c7ef3b8d0ff7f",
            "8b59947d77884861b4d49def64e082db",
            "7971bad7d6544aaaa4a638ad3a6a1cd0",
            "3a84b6ab7cc6473285da0986876199a6",
            "4684ea77369841c2a6964502a170acc3",
            "ddb0eefaaae74df68894e39b565d88e9",
            "10e524325fd04c518400bf8f810cae16",
            "a12719307b174d2db232dc90af3553e1"
          ]
        },
        "id": "yoJ4b8v-YKDI",
        "outputId": "717840e8-27b9-4e4f-b85d-dcfc87191a22"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8a2ea7acbf442bc8f08ce4a5f6ebf45",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/467M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n",
            "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'sequence_summary.summary.bias', 'logits_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import XLNetForSequenceClassification\n",
        "model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels = 2)\n",
        "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mucRq1owYJ_5",
        "outputId": "9c318639-9c38-4dda-a848-cd9f222cbd60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "XLNetForSequenceClassification(\n",
              "  (transformer): XLNetModel(\n",
              "    (word_embedding): Embedding(32000, 768)\n",
              "    (layer): ModuleList(\n",
              "      (0): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (3): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (4): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (5): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (6): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (7): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (8): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (9): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (10): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (11): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (sequence_summary): SequenceSummary(\n",
              "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "    (first_dropout): Identity()\n",
              "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (logits_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRThd-49YJ8u"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 4\n",
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "                                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "                                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay':0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)\n",
        "\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v021Ba2BYJ5s",
        "outputId": "5c7c32dd-83a6-4c73-e744-6d7e46ce730f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = next(iter(val_data_loader))\n",
        "data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiLPnVAKYJ2S",
        "outputId": "799d4108-fe7b-4649-8a9f-228f3d46888a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n"
          ]
        }
      ],
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "targets = data['targets'].to(device)\n",
        "print(input_ids.reshape(-1,512).shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSmjLs-8YJzK",
        "outputId": "f1d3662a-5332-461e-faec-15e739641e0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 8113,  8038,  2983, 12698, 15221,  6997,  1614,   811,  1539,  2307,\n",
              "          1042, 24107,   146,   493, 18839,   297,     4,     3,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0]], device='cuda:0')"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_ids[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1uVfu2vYJwk",
        "outputId": "7b17d604-e733-43c8-9b01-7bb539a8396e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "XLNetForSequenceClassificationOutput(loss=tensor(0.7434, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.1177e-01, -6.5801e-01],\n",
              "        [-2.8439e-04, -9.0551e-01],\n",
              "        [-1.8818e-01, -5.3363e-01],\n",
              "        [-1.0941e-01, -7.7579e-01],\n",
              "        [-1.3517e-01, -6.5024e-01],\n",
              "        [-1.0937e-01, -6.9294e-01],\n",
              "        [-9.7291e-02, -6.8219e-01],\n",
              "        [-1.3901e-01, -8.6226e-01]], device='cuda:0', grad_fn=<AddmmBackward0>), mems=(tensor([[[ 4.8711e-03,  5.2800e-02,  4.2355e-02,  ...,  1.3304e-03,\n",
              "           6.5146e-03, -1.2271e-01],\n",
              "         [-3.8695e-02, -9.8694e-03, -5.3354e-03,  ...,  6.4287e-02,\n",
              "           1.9249e-02, -1.4396e-02],\n",
              "         [-3.8695e-02, -9.8694e-03, -5.3354e-03,  ...,  6.4287e-02,\n",
              "           1.9249e-02, -1.4396e-02],\n",
              "         ...,\n",
              "         [-3.8695e-02, -9.8694e-03, -5.3354e-03,  ...,  6.4287e-02,\n",
              "           1.9249e-02, -1.4396e-02],\n",
              "         [-3.8695e-02, -9.8694e-03, -5.3354e-03,  ...,  6.4287e-02,\n",
              "           1.9249e-02, -1.4396e-02],\n",
              "         [ 3.7776e-05, -7.8475e-03,  5.5150e-02,  ...,  6.4801e-03,\n",
              "           9.6704e-02, -4.5320e-02]],\n",
              "\n",
              "        [[-3.2006e-02, -1.6051e-01,  3.4198e-02,  ...,  4.9979e-02,\n",
              "           1.9793e-02, -5.0492e-02],\n",
              "         [-1.4033e-01,  1.7266e-02, -3.8260e-03,  ...,  1.0473e-01,\n",
              "          -3.2920e-03,  2.6519e-02],\n",
              "         [ 2.2712e-02,  6.4040e-02,  3.0965e-02,  ...,  1.9347e-02,\n",
              "          -7.7706e-02,  5.4655e-02],\n",
              "         ...,\n",
              "         [ 1.4622e-01,  3.2346e-02, -5.8874e-02,  ...,  5.7938e-02,\n",
              "           4.0387e-02, -5.2847e-02],\n",
              "         [ 2.5049e-02,  4.6983e-02, -1.7045e-02,  ...,  3.3101e-03,\n",
              "           5.3492e-03, -4.8687e-04],\n",
              "         [-1.5924e-02,  4.1147e-02,  1.6892e-03,  ...,  6.3449e-03,\n",
              "          -6.4257e-03,  6.0507e-03]],\n",
              "\n",
              "        [[-1.7605e-02, -9.0635e-03,  2.3280e-02,  ..., -3.2700e-02,\n",
              "          -7.1492e-02, -9.1489e-02],\n",
              "         [ 1.8875e-02,  7.0670e-02,  1.1309e-02,  ...,  7.0852e-02,\n",
              "           9.5652e-03,  1.1023e-01],\n",
              "         [ 5.3921e-02, -2.3418e-02,  9.7098e-02,  ...,  8.0537e-02,\n",
              "          -1.9824e-02,  6.8056e-02],\n",
              "         ...,\n",
              "         [ 2.3302e-02,  2.7787e-02,  3.4115e-02,  ...,  1.3168e-01,\n",
              "          -7.1608e-02, -2.3893e-02],\n",
              "         [-4.5636e-02,  6.0948e-02,  5.0727e-02,  ...,  5.2602e-02,\n",
              "           4.0187e-03, -6.5506e-02],\n",
              "         [ 2.6747e-02,  4.1164e-02, -1.4551e-02,  ...,  1.0746e-02,\n",
              "           5.3777e-02, -3.8488e-02]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-4.8919e-03,  6.5530e-02, -1.5061e-02,  ..., -4.5812e-02,\n",
              "          -6.1461e-03,  3.4621e-02],\n",
              "         [-4.8919e-03,  6.5530e-02, -1.5061e-02,  ..., -4.5812e-02,\n",
              "          -6.1461e-03,  3.4621e-02],\n",
              "         [-4.8919e-03,  6.5530e-02, -1.5061e-02,  ..., -4.5812e-02,\n",
              "          -6.1461e-03,  3.4621e-02],\n",
              "         ...,\n",
              "         [-4.8919e-03,  6.5530e-02, -1.5061e-02,  ..., -4.5812e-02,\n",
              "          -6.1461e-03,  3.4621e-02],\n",
              "         [-4.8919e-03,  6.5530e-02, -1.5061e-02,  ..., -4.5812e-02,\n",
              "          -6.1461e-03,  3.4621e-02],\n",
              "         [-4.8919e-03,  6.5530e-02, -1.5061e-02,  ..., -4.5812e-02,\n",
              "          -6.1461e-03,  3.4621e-02]],\n",
              "\n",
              "        [[-4.8919e-03,  6.5530e-02, -1.5061e-02,  ..., -4.5812e-02,\n",
              "          -6.1461e-03,  3.4621e-02],\n",
              "         [-4.8919e-03,  6.5530e-02, -1.5061e-02,  ..., -4.5812e-02,\n",
              "          -6.1461e-03,  3.4621e-02],\n",
              "         [-4.8919e-03,  6.5530e-02, -1.5061e-02,  ..., -4.5812e-02,\n",
              "          -6.1461e-03,  3.4621e-02],\n",
              "         ...,\n",
              "         [-4.8919e-03,  6.5530e-02, -1.5061e-02,  ..., -4.5812e-02,\n",
              "          -6.1461e-03,  3.4621e-02],\n",
              "         [-4.8919e-03,  6.5530e-02, -1.5061e-02,  ..., -4.5812e-02,\n",
              "          -6.1461e-03,  3.4621e-02],\n",
              "         [-4.8919e-03,  6.5530e-02, -1.5061e-02,  ..., -4.5812e-02,\n",
              "          -6.1461e-03,  3.4621e-02]],\n",
              "\n",
              "        [[-4.8919e-03,  6.5530e-02, -1.5061e-02,  ..., -4.5812e-02,\n",
              "          -6.1461e-03,  3.4621e-02],\n",
              "         [-4.8919e-03,  6.5530e-02, -1.5061e-02,  ..., -4.5812e-02,\n",
              "          -6.1461e-03,  3.4621e-02],\n",
              "         [-4.8919e-03,  6.5530e-02, -1.5061e-02,  ..., -4.5812e-02,\n",
              "          -6.1461e-03,  3.4621e-02],\n",
              "         ...,\n",
              "         [-4.8919e-03,  6.5530e-02, -1.5061e-02,  ..., -4.5812e-02,\n",
              "          -6.1461e-03,  3.4621e-02],\n",
              "         [-4.8919e-03,  6.5530e-02, -1.5061e-02,  ..., -4.5812e-02,\n",
              "          -6.1461e-03,  3.4621e-02],\n",
              "         [-4.8919e-03,  6.5530e-02, -1.5061e-02,  ..., -4.5812e-02,\n",
              "          -6.1461e-03,  3.4621e-02]]], device='cuda:0'), tensor([[[ 0.7137,  1.2266,  0.1315,  ..., -0.3464, -0.1010, -1.8179],\n",
              "         [-0.4375,  0.6572,  0.6924,  ...,  0.3416,  0.0615,  0.9981],\n",
              "         [-0.3556,  0.5196,  0.5268,  ...,  0.0666, -0.1902,  1.0619],\n",
              "         ...,\n",
              "         [-0.2806,  0.3647,  0.3771,  ...,  0.1854,  0.0090,  1.0816],\n",
              "         [-0.8869,  0.2959,  0.1409,  ...,  0.2391, -0.1706,  1.0727],\n",
              "         [-0.6202, -0.2115,  0.4094,  ...,  0.0525,  1.9390, -1.0305]],\n",
              "\n",
              "        [[ 0.0925, -3.3221,  0.0501,  ...,  1.0897, -0.0240, -1.4295],\n",
              "         [-2.7953,  0.2178,  0.3676,  ...,  1.4045,  0.0531,  0.2143],\n",
              "         [-0.7178,  1.1416,  0.9217,  ..., -0.1831, -1.3619,  0.6490],\n",
              "         ...,\n",
              "         [ 1.8888,  0.3917, -0.7141,  ...,  0.6395,  0.1666, -0.2901],\n",
              "         [-0.1447,  0.8843, -0.5288,  ...,  0.4115, -1.0098,  0.6720],\n",
              "         [-0.4253,  1.0828,  0.0971,  ..., -1.2614,  0.3926,  0.2932]],\n",
              "\n",
              "        [[ 0.4455,  0.4104,  0.4784,  ..., -0.6246, -1.1178, -0.4800],\n",
              "         [ 0.8503,  1.9720,  1.0824,  ...,  0.4389, -0.0953,  1.6221],\n",
              "         [ 1.2674, -0.0253,  2.2203,  ...,  1.0308, -0.7984,  1.1297],\n",
              "         ...,\n",
              "         [ 0.5976,  1.1049,  1.1372,  ...,  1.4361, -0.9018, -0.4360],\n",
              "         [-0.6081,  1.6406,  0.8118,  ...,  0.6161,  0.3652, -1.2691],\n",
              "         [ 0.7060,  0.9483, -0.3148,  ..., -0.1822,  1.5382, -0.9944]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.0675,  2.4868,  0.3182,  ..., -0.2316, -1.9128,  0.8620],\n",
              "         [ 0.0882,  2.0803,  0.3238,  ..., -0.8418, -1.4988,  0.7169],\n",
              "         [ 0.4276,  1.9961,  0.2496,  ..., -0.8816, -1.3178,  0.5746],\n",
              "         ...,\n",
              "         [ 0.2964,  1.9007,  0.1309,  ..., -0.7046, -1.0194,  0.5195],\n",
              "         [ 0.1534,  2.1067,  0.3178,  ..., -0.8507, -1.3525,  0.8077],\n",
              "         [-0.0189,  2.0589,  0.1816,  ..., -0.8606, -1.1771,  0.5980]],\n",
              "\n",
              "        [[ 0.0826,  2.4688,  0.3128,  ..., -0.2370, -1.9008,  0.8559],\n",
              "         [ 0.0822,  2.1156,  0.3073,  ..., -0.8434, -1.5325,  0.7295],\n",
              "         [ 0.4350,  2.0074,  0.2553,  ..., -0.8739, -1.3125,  0.5854],\n",
              "         ...,\n",
              "         [ 0.3009,  1.9210,  0.1560,  ..., -0.6933, -1.0545,  0.5202],\n",
              "         [ 0.1420,  2.1270,  0.3076,  ..., -0.8310, -1.3910,  0.8301],\n",
              "         [-0.0057,  2.0680,  0.1932,  ..., -0.8554, -1.1860,  0.6276]],\n",
              "\n",
              "        [[ 0.1052,  2.4617,  0.3036,  ..., -0.2301, -1.8905,  0.8494],\n",
              "         [ 0.0813,  2.1391,  0.2666,  ..., -0.8300, -1.5556,  0.7473],\n",
              "         [ 0.4331,  2.0264,  0.2459,  ..., -0.8665, -1.3027,  0.5813],\n",
              "         ...,\n",
              "         [ 0.3190,  1.9594,  0.1707,  ..., -0.6648, -1.0807,  0.5523],\n",
              "         [ 0.1283,  2.1473,  0.2929,  ..., -0.8015, -1.4195,  0.8423],\n",
              "         [ 0.0203,  2.0634,  0.1932,  ..., -0.8612, -1.2198,  0.6348]]],\n",
              "       device='cuda:0'), tensor([[[ 5.4210e-02,  5.9191e-03,  3.6185e-02,  ...,  5.9539e-01,\n",
              "           2.8798e-01, -1.1437e+00],\n",
              "         [ 6.0419e-02,  6.3092e-01,  4.8239e-01,  ...,  3.0006e-01,\n",
              "          -3.9102e-01,  4.7927e-01],\n",
              "         [-4.1741e-01,  5.8883e-01,  5.2483e-01,  ..., -7.2471e-03,\n",
              "          -5.8698e-01,  6.9577e-01],\n",
              "         ...,\n",
              "         [-2.6842e-01,  2.1679e-01,  2.9784e-01,  ..., -2.8098e-01,\n",
              "           3.2958e-01,  6.9623e-01],\n",
              "         [-9.6843e-01,  2.2094e-01, -1.3300e-01,  ...,  2.1638e-01,\n",
              "          -3.6572e-01,  5.3600e-01],\n",
              "         [-4.5541e-01,  5.1528e-01,  5.4589e-01,  ...,  2.4460e-01,\n",
              "           1.6300e+00, -8.5770e-01]],\n",
              "\n",
              "        [[-5.5986e-01, -2.3307e+00,  3.1017e-01,  ...,  1.0352e+00,\n",
              "          -1.0007e-01, -9.9370e-01],\n",
              "         [-1.5021e+00,  6.0751e-01,  5.9495e-01,  ...,  4.8583e-01,\n",
              "           4.2081e-01, -2.4395e-01],\n",
              "         [-9.1564e-01,  8.3440e-01,  1.0331e+00,  ...,  4.9843e-01,\n",
              "          -1.0717e+00,  4.9364e-01],\n",
              "         ...,\n",
              "         [ 9.6902e-01, -8.5798e-03,  1.5469e-01,  ...,  1.1800e-01,\n",
              "           4.1216e-01, -7.0322e-01],\n",
              "         [-6.3203e-01,  7.4263e-01,  1.0449e-01,  ...,  7.3766e-01,\n",
              "          -3.1866e-01,  4.7512e-01],\n",
              "         [-4.2398e-01,  8.7554e-01, -1.3789e-01,  ..., -8.7921e-01,\n",
              "           1.0896e+00, -4.0526e-01]],\n",
              "\n",
              "        [[ 2.1953e-02, -3.0449e-01,  1.2851e+00,  ..., -4.4993e-01,\n",
              "          -6.0717e-01,  1.4444e-01],\n",
              "         [ 1.3812e+00,  1.7739e+00,  1.2957e+00,  ..., -9.7173e-01,\n",
              "          -2.8907e-01,  2.1429e-01],\n",
              "         [ 7.1247e-01, -1.8002e-01,  1.8503e+00,  ...,  1.0746e+00,\n",
              "          -7.4734e-01,  2.1770e-01],\n",
              "         ...,\n",
              "         [ 3.6870e-01, -4.1928e-02,  2.0063e+00,  ...,  5.0242e-01,\n",
              "           4.8568e-01, -1.2941e+00],\n",
              "         [-1.0084e+00,  1.4058e+00,  1.0267e-04,  ...,  1.0507e+00,\n",
              "          -5.4485e-01, -1.1899e+00],\n",
              "         [ 3.6193e-01,  4.9147e-01, -6.1765e-01,  ...,  6.7623e-02,\n",
              "           2.0180e+00, -1.1196e+00]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-2.0250e-01,  2.2945e+00,  9.6401e-01,  ...,  2.0442e-01,\n",
              "          -1.7492e+00,  9.1306e-01],\n",
              "         [ 8.4639e-02,  2.0118e+00,  1.2313e+00,  ..., -2.2986e-01,\n",
              "          -1.2314e+00,  3.6610e-01],\n",
              "         [-6.8012e-03,  1.5241e+00,  1.3719e+00,  ..., -4.3316e-02,\n",
              "          -1.3073e+00,  2.5837e-01],\n",
              "         ...,\n",
              "         [-7.6729e-03,  1.5943e+00,  1.0569e+00,  ...,  3.2865e-02,\n",
              "          -1.0594e+00,  9.9918e-02],\n",
              "         [-1.1903e-01,  1.9778e+00,  1.0456e+00,  ..., -2.9105e-01,\n",
              "          -1.2728e+00,  6.5234e-01],\n",
              "         [-4.8371e-01,  1.8089e+00,  1.1953e+00,  ..., -3.5041e-01,\n",
              "          -9.9541e-01,  5.9811e-01]],\n",
              "\n",
              "        [[-1.8103e-01,  2.2839e+00,  9.5327e-01,  ...,  2.1050e-01,\n",
              "          -1.7479e+00,  8.7610e-01],\n",
              "         [ 1.0253e-01,  1.9765e+00,  1.1420e+00,  ..., -2.8032e-01,\n",
              "          -1.2020e+00,  3.3999e-01],\n",
              "         [-5.2482e-03,  1.5239e+00,  1.3810e+00,  ..., -7.2540e-03,\n",
              "          -1.3042e+00,  2.6523e-01],\n",
              "         ...,\n",
              "         [-3.7809e-02,  1.5374e+00,  1.0787e+00,  ..., -5.8259e-02,\n",
              "          -1.0295e+00,  6.8164e-02],\n",
              "         [-1.2228e-01,  2.0123e+00,  9.8135e-01,  ..., -2.4177e-01,\n",
              "          -1.2792e+00,  6.5073e-01],\n",
              "         [-4.4520e-01,  1.7635e+00,  1.1688e+00,  ..., -4.0508e-01,\n",
              "          -9.7784e-01,  6.3978e-01]],\n",
              "\n",
              "        [[-1.4683e-01,  2.2977e+00,  9.5577e-01,  ...,  2.3847e-01,\n",
              "          -1.7430e+00,  8.4924e-01],\n",
              "         [ 7.8768e-02,  1.9747e+00,  1.0645e+00,  ..., -2.4890e-01,\n",
              "          -1.1968e+00,  3.5508e-01],\n",
              "         [-2.9924e-02,  1.5330e+00,  1.3778e+00,  ...,  3.9055e-02,\n",
              "          -1.3234e+00,  2.7307e-01],\n",
              "         ...,\n",
              "         [-5.3127e-02,  1.5234e+00,  1.0453e+00,  ..., -7.2695e-02,\n",
              "          -1.0553e+00,  8.0291e-02],\n",
              "         [-1.5758e-01,  2.0543e+00,  9.1490e-01,  ..., -1.6853e-01,\n",
              "          -1.3011e+00,  6.6957e-01],\n",
              "         [-4.0813e-01,  1.6853e+00,  1.1144e+00,  ..., -4.0784e-01,\n",
              "          -9.9604e-01,  6.4344e-01]]], device='cuda:0'), tensor([[[-9.0593e-01, -4.4251e-01, -5.9938e-01,  ...,  8.3016e-01,\n",
              "           6.2748e-01, -1.1213e+00],\n",
              "         [-5.2827e-01,  1.5358e+00,  7.5113e-01,  ...,  7.4315e-02,\n",
              "           1.4088e-01, -2.4016e-01],\n",
              "         [-2.7974e-01,  3.1408e-01,  5.7085e-01,  ...,  2.7843e-01,\n",
              "          -3.1329e-01,  5.9321e-02],\n",
              "         ...,\n",
              "         [-4.8871e-01, -6.2367e-02,  5.4102e-01,  ...,  7.8728e-01,\n",
              "           1.2476e-01,  2.1031e-01],\n",
              "         [-8.6990e-01, -5.6014e-01, -2.1524e-01,  ...,  4.4711e-01,\n",
              "          -1.5658e-01,  4.8876e-01],\n",
              "         [-7.6250e-01,  6.5503e-01, -3.2130e-01,  ...,  3.9205e-02,\n",
              "           2.3385e+00, -1.2364e+00]],\n",
              "\n",
              "        [[-8.8419e-01, -2.4962e+00,  1.9173e-01,  ...,  9.8052e-01,\n",
              "          -3.2711e-02, -1.7029e+00],\n",
              "         [-1.3517e+00,  1.1414e+00,  9.0457e-01,  ...,  3.5605e-01,\n",
              "           2.0280e-01, -1.2787e+00],\n",
              "         [-5.7433e-01,  6.3378e-01,  4.4528e-01,  ...,  1.8125e-01,\n",
              "          -8.3786e-01, -3.4895e-01],\n",
              "         ...,\n",
              "         [ 6.5286e-01,  1.7171e-02,  3.1780e-01,  ...,  9.2168e-01,\n",
              "          -4.0495e-02, -1.2152e+00],\n",
              "         [-6.5133e-01,  4.2102e-01, -3.3974e-01,  ...,  1.2314e+00,\n",
              "          -2.7607e-01, -1.6161e-01],\n",
              "         [-8.5992e-01,  2.7730e-01, -6.3973e-01,  ..., -1.1032e+00,\n",
              "           1.2004e+00, -6.5730e-01]],\n",
              "\n",
              "        [[-6.0387e-01, -4.9832e-01,  1.2371e+00,  ...,  1.4127e-02,\n",
              "          -8.7796e-01, -2.6707e-01],\n",
              "         [ 3.5368e-01,  2.9398e+00,  1.1026e+00,  ..., -1.2750e+00,\n",
              "          -3.0859e-01, -1.2403e+00],\n",
              "         [ 5.9078e-01, -3.3180e-01,  1.0486e+00,  ...,  7.5829e-01,\n",
              "          -5.5373e-01, -5.7525e-01],\n",
              "         ...,\n",
              "         [ 1.6927e-01, -7.0305e-02,  1.6895e+00,  ...,  4.3766e-01,\n",
              "           3.5008e-01, -1.4723e+00],\n",
              "         [-8.7357e-01,  1.2657e+00,  1.5625e-01,  ...,  8.2578e-01,\n",
              "          -2.3171e-03, -1.6300e+00],\n",
              "         [ 9.5643e-02,  5.5978e-01, -1.6798e+00,  ..., -1.1211e+00,\n",
              "           2.8046e+00, -1.4579e+00]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.0191e-01,  3.3725e+00,  5.9760e-01,  ..., -1.1624e-01,\n",
              "          -2.6522e+00,  3.8659e-01],\n",
              "         [-1.1650e-01,  2.7881e+00,  8.0244e-01,  ..., -4.1304e-01,\n",
              "          -1.9853e+00,  2.9700e-02],\n",
              "         [-1.5924e-01,  2.3359e+00,  6.4864e-01,  ...,  1.9807e-01,\n",
              "          -2.3520e+00, -2.7890e-01],\n",
              "         ...,\n",
              "         [-4.0040e-02,  3.1275e+00,  9.4050e-01,  ...,  4.4242e-01,\n",
              "          -2.2557e+00, -5.2699e-01],\n",
              "         [-1.5037e-01,  3.0072e+00,  7.9279e-01,  ..., -2.8430e-01,\n",
              "          -2.1555e+00, -1.5705e-01],\n",
              "         [-4.0545e-01,  2.8216e+00,  8.9469e-01,  ..., -7.7373e-01,\n",
              "          -1.5076e+00,  4.1687e-01]],\n",
              "\n",
              "        [[-8.8985e-02,  3.3961e+00,  6.4388e-01,  ..., -7.9204e-02,\n",
              "          -2.6947e+00,  3.5646e-01],\n",
              "         [-7.1524e-02,  2.7277e+00,  7.3933e-01,  ..., -6.0219e-01,\n",
              "          -2.0059e+00, -3.4708e-02],\n",
              "         [-1.5062e-01,  2.3274e+00,  6.7028e-01,  ...,  2.3378e-01,\n",
              "          -2.3635e+00, -2.6889e-01],\n",
              "         ...,\n",
              "         [-4.0038e-02,  3.0409e+00,  9.8044e-01,  ...,  2.7108e-01,\n",
              "          -2.2986e+00, -5.4918e-01],\n",
              "         [-1.4599e-01,  2.9814e+00,  7.2403e-01,  ..., -3.1448e-01,\n",
              "          -2.1520e+00, -1.3552e-01],\n",
              "         [-3.4924e-01,  2.7677e+00,  9.3874e-01,  ..., -9.1058e-01,\n",
              "          -1.5056e+00,  4.2287e-01]],\n",
              "\n",
              "        [[-5.3838e-02,  3.4015e+00,  6.6946e-01,  ..., -1.2969e-02,\n",
              "          -2.7351e+00,  3.5397e-01],\n",
              "         [-6.3870e-02,  2.6804e+00,  6.6836e-01,  ..., -6.6912e-01,\n",
              "          -2.0471e+00,  1.4989e-02],\n",
              "         [-1.9025e-01,  2.3445e+00,  6.5643e-01,  ...,  3.0636e-01,\n",
              "          -2.3781e+00, -3.1166e-01],\n",
              "         ...,\n",
              "         [-3.1811e-02,  2.9524e+00,  9.5413e-01,  ...,  1.9057e-01,\n",
              "          -2.3538e+00, -4.6438e-01],\n",
              "         [-1.7816e-01,  3.0345e+00,  6.2163e-01,  ..., -2.1149e-01,\n",
              "          -2.1621e+00, -1.3500e-01],\n",
              "         [-2.7254e-01,  2.6295e+00,  9.2026e-01,  ..., -9.5592e-01,\n",
              "          -1.5179e+00,  4.6188e-01]]], device='cuda:0'), tensor([[[-0.8184, -0.7655,  0.5208,  ...,  1.2412, -0.2148,  0.3589],\n",
              "         [-0.3514,  0.4290,  0.9732,  ...,  1.9603,  0.4759,  1.4608],\n",
              "         [ 1.1046, -0.0976,  0.3691,  ...,  0.7737,  0.0248,  0.7515],\n",
              "         ...,\n",
              "         [ 0.9390, -0.6239,  0.9288,  ...,  1.0550, -0.0336,  1.1838],\n",
              "         [-0.3143, -0.7508, -0.3485,  ...,  0.6715, -0.2842,  0.8027],\n",
              "         [ 0.1413, -0.0254,  0.1875,  ...,  0.5606,  2.1298, -0.0449]],\n",
              "\n",
              "        [[-0.4996, -1.7830,  1.2068,  ...,  0.9519, -0.5451,  0.0769],\n",
              "         [-1.5136,  0.5593,  1.0715,  ...,  2.2309,  0.3148, -0.0185],\n",
              "         [ 0.1093,  0.1194,  0.2437,  ...,  1.1508, -0.3784, -0.0363],\n",
              "         ...,\n",
              "         [ 1.8033, -0.3498,  0.8466,  ...,  1.3810,  0.0768,  0.1035],\n",
              "         [-0.5875,  0.1419, -0.0380,  ...,  1.5852, -0.8633,  0.2720],\n",
              "         [-0.0506, -0.1100,  0.0508,  ..., -0.8189,  0.5608,  0.5576]],\n",
              "\n",
              "        [[-0.0247, -0.3788,  1.4296,  ...,  0.6361, -1.8116,  1.3229],\n",
              "         [ 1.0237,  2.0308,  1.0103,  ...,  0.7904,  0.2280, -0.3831],\n",
              "         [ 1.9997, -0.8239,  0.5698,  ...,  1.6824, -0.5828, -0.0726],\n",
              "         ...,\n",
              "         [ 1.4139, -0.2296,  1.7007,  ...,  1.0983,  0.5413, -0.2557],\n",
              "         [-0.5582,  0.9629,  0.2862,  ...,  1.0041,  0.0235, -1.1378],\n",
              "         [ 0.7205,  0.4600, -1.0881,  ..., -0.4295,  1.7707,  0.0919]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.2505,  2.6920,  0.6480,  ...,  1.1368, -2.7814,  0.6938],\n",
              "         [ 0.6649,  2.1797,  0.6388,  ...,  1.2068, -1.3900,  0.2279],\n",
              "         [ 0.6581,  2.1897,  0.2416,  ...,  1.0212, -1.9241, -0.1193],\n",
              "         ...,\n",
              "         [ 0.7482,  2.4211,  0.8459,  ...,  1.5738, -1.8484, -0.1301],\n",
              "         [ 0.2870,  2.6118,  0.6476,  ...,  1.1770, -1.6927,  0.0266],\n",
              "         [ 0.5262,  2.1810,  0.4131,  ...,  0.2491, -0.6400, -0.0392]],\n",
              "\n",
              "        [[ 0.3086,  2.6805,  0.6742,  ...,  1.1696, -2.8046,  0.6630],\n",
              "         [ 0.6885,  2.1572,  0.5815,  ...,  1.0081, -1.4317,  0.0157],\n",
              "         [ 0.6816,  2.1660,  0.2508,  ...,  1.0379, -1.9147, -0.1053],\n",
              "         ...,\n",
              "         [ 0.6334,  2.4381,  0.8573,  ...,  1.3877, -1.9056, -0.1202],\n",
              "         [ 0.2783,  2.5876,  0.5307,  ...,  1.2197, -1.7196, -0.1502],\n",
              "         [ 0.5801,  2.1720,  0.4676,  ...,  0.1066, -0.6008, -0.0798]],\n",
              "\n",
              "        [[ 0.3732,  2.6489,  0.6934,  ...,  1.2162, -2.8148,  0.6563],\n",
              "         [ 0.7200,  2.1174,  0.5346,  ...,  0.9377, -1.5110, -0.1133],\n",
              "         [ 0.6226,  2.1573,  0.2462,  ...,  1.0863, -1.9232, -0.1228],\n",
              "         ...,\n",
              "         [ 0.6243,  2.3902,  0.8396,  ...,  1.2808, -2.0111, -0.1721],\n",
              "         [ 0.1854,  2.6652,  0.4176,  ...,  1.3270, -1.7353, -0.1719],\n",
              "         [ 0.6839,  2.0762,  0.4425,  ...,  0.1048, -0.6121, -0.0837]]],\n",
              "       device='cuda:0'), tensor([[[-0.5006,  0.3003, -0.2487,  ...,  0.3739, -0.7797, -0.3329],\n",
              "         [ 0.0184,  1.5641,  0.3832,  ...,  0.6216, -1.6363,  0.2043],\n",
              "         [ 0.8283,  0.9477,  0.4475,  ..., -0.0183, -0.5447, -0.4687],\n",
              "         ...,\n",
              "         [ 0.8950,  0.4600,  0.8193,  ...,  0.0164, -0.8143,  0.0645],\n",
              "         [-0.8559,  0.0743, -0.6550,  ..., -0.1053, -1.3869, -0.8034],\n",
              "         [-0.2928,  0.2203,  0.0279,  ..., -0.5003,  0.2051, -1.3084]],\n",
              "\n",
              "        [[-0.7031, -0.3418, -0.1315,  ...,  0.4071, -1.1456, -0.3615],\n",
              "         [-0.7789,  1.7316,  0.7260,  ...,  0.6750, -1.7943, -0.5764],\n",
              "         [ 0.0436,  1.1402,  0.6333,  ...,  0.0116, -0.7410, -0.6546],\n",
              "         ...,\n",
              "         [ 1.6838,  0.4280,  0.7875,  ...,  0.1505, -0.7251, -0.4521],\n",
              "         [-1.1685,  0.6560, -0.0477,  ...,  0.5436, -1.5284, -1.1950],\n",
              "         [-0.6155,  0.2413, -0.1683,  ..., -1.1526, -1.2299, -0.9233]],\n",
              "\n",
              "        [[-0.6610,  0.6182,  0.2686,  ..., -0.0475, -2.1578,  0.7729],\n",
              "         [ 0.5931,  2.4302,  0.4368,  ..., -0.0632, -1.5500, -0.7171],\n",
              "         [ 1.2577,  0.2811,  0.6769,  ...,  0.4286, -1.1212, -0.5162],\n",
              "         ...,\n",
              "         [ 1.4134,  0.3885,  1.2989,  ...,  0.0647, -0.8446, -0.8627],\n",
              "         [-1.2568,  1.2555, -0.0846,  ...,  0.2481, -0.8389, -1.7299],\n",
              "         [-0.5915,  0.9110, -0.8971,  ..., -1.0761, -0.1323, -1.3130]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.8848,  2.4888,  0.3199,  ...,  0.3421, -2.0180,  0.5127],\n",
              "         [ 0.8730,  2.5250,  0.3026,  ...,  0.3493, -1.2755, -0.0327],\n",
              "         [ 1.0747,  2.2707, -0.1177,  ...,  0.4132, -1.4272,  0.0762],\n",
              "         ...,\n",
              "         [ 1.1682,  2.0058,  0.2625,  ...,  0.4761, -1.3877,  0.0853],\n",
              "         [ 0.3040,  2.5436, -0.0571,  ...,  0.2927, -1.2302, -0.1292],\n",
              "         [ 0.8692,  2.2393,  0.4401,  ..., -0.3608, -0.4900, -0.0645]],\n",
              "\n",
              "        [[ 0.9337,  2.4845,  0.3520,  ...,  0.3909, -2.0219,  0.4994],\n",
              "         [ 0.9111,  2.5193,  0.2553,  ...,  0.2099, -1.3467, -0.2039],\n",
              "         [ 1.1044,  2.2419, -0.1270,  ...,  0.4459, -1.4093,  0.1003],\n",
              "         ...,\n",
              "         [ 1.0752,  2.0352,  0.2309,  ...,  0.3787, -1.4280,  0.0816],\n",
              "         [ 0.3824,  2.5172, -0.1961,  ...,  0.3987, -1.3606, -0.2201],\n",
              "         [ 0.9065,  2.2575,  0.4415,  ..., -0.4168, -0.5529, -0.1958]],\n",
              "\n",
              "        [[ 0.9965,  2.4825,  0.3736,  ...,  0.4835, -2.0047,  0.5327],\n",
              "         [ 0.9644,  2.4675,  0.2160,  ...,  0.1796, -1.4730, -0.2816],\n",
              "         [ 1.0571,  2.2264, -0.1362,  ...,  0.4846, -1.3757,  0.1378],\n",
              "         ...,\n",
              "         [ 1.0687,  1.9701,  0.1658,  ...,  0.3471, -1.5445,  0.0717],\n",
              "         [ 0.3701,  2.5970, -0.2669,  ...,  0.4612, -1.4058, -0.1688],\n",
              "         [ 0.9680,  2.1780,  0.3738,  ..., -0.3694, -0.6222, -0.2488]]],\n",
              "       device='cuda:0'), tensor([[[-0.8072,  0.4892, -0.6490,  ...,  0.5248, -1.8362, -0.4055],\n",
              "         [-0.0682,  2.3592,  0.8190,  ...,  0.2210, -2.3876,  0.5654],\n",
              "         [ 0.7621,  0.9195,  0.5610,  ...,  0.7840, -1.5005, -0.6297],\n",
              "         ...,\n",
              "         [ 0.1683,  0.1997,  0.4069,  ...,  0.8251, -1.6334,  0.0149],\n",
              "         [-0.5252,  0.1495, -0.6151,  ...,  0.2734, -2.0339, -1.1186],\n",
              "         [ 0.1239,  0.4629,  0.0678,  ..., -1.5778, -0.5124, -1.2180]],\n",
              "\n",
              "        [[-0.8939,  0.1499, -0.9730,  ...,  0.0271, -1.8684, -0.6729],\n",
              "         [-1.0576,  2.7611,  1.1326,  ...,  0.6647, -2.6717, -0.0380],\n",
              "         [ 0.1060,  1.3094,  0.8808,  ...,  1.3561, -1.4003, -1.2583],\n",
              "         ...,\n",
              "         [ 1.0032,  0.6401,  0.4393,  ...,  1.1485, -1.8736, -0.6271],\n",
              "         [-0.9564,  0.7424,  0.0956,  ...,  1.4126, -2.1586, -1.7766],\n",
              "         [-0.3425,  0.4753,  0.1543,  ..., -1.4412, -1.7812, -0.9641]],\n",
              "\n",
              "        [[-0.8785,  1.0653, -0.3287,  ..., -0.2836, -3.1740,  0.2559],\n",
              "         [ 0.4375,  3.5439,  0.4127,  ..., -0.1545, -2.2334, -0.4430],\n",
              "         [ 1.2111,  0.2538,  1.1201,  ...,  1.8887, -2.0761, -1.0928],\n",
              "         ...,\n",
              "         [ 0.9500,  0.6772,  1.0518,  ...,  1.2500, -2.0862, -1.4021],\n",
              "         [-0.8382,  1.5301, -0.0262,  ...,  0.9910, -1.7139, -2.4764],\n",
              "         [-0.6729,  1.3194, -1.0356,  ..., -0.7553, -0.3343, -1.8043]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.8181,  3.6490,  0.4094,  ...,  0.9316, -2.2699,  0.8587],\n",
              "         [ 0.7647,  3.1607,  0.5480,  ...,  0.8996, -1.7383,  0.0996],\n",
              "         [ 0.8273,  3.0937, -0.5865,  ...,  1.0068, -1.7129, -0.2203],\n",
              "         ...,\n",
              "         [ 0.6520,  2.6449,  0.1628,  ...,  1.1352, -2.1572,  0.1571],\n",
              "         [ 0.3481,  3.1695,  0.3721,  ...,  1.3645, -1.4259, -0.3603],\n",
              "         [ 0.9191,  2.3361,  1.1347,  ...,  0.5530, -0.1622, -0.1255]],\n",
              "\n",
              "        [[ 0.8562,  3.6267,  0.4890,  ...,  1.0121, -2.2020,  0.9054],\n",
              "         [ 0.6613,  3.0909,  0.4804,  ...,  0.6765, -1.6181,  0.0430],\n",
              "         [ 0.8304,  3.1066, -0.5838,  ...,  1.0570, -1.6873, -0.1757],\n",
              "         ...,\n",
              "         [ 0.4838,  2.7220,  0.0370,  ...,  0.8804, -1.9769,  0.2987],\n",
              "         [ 0.3795,  3.2107,  0.1707,  ...,  1.4182, -1.2540, -0.2548],\n",
              "         [ 0.9563,  2.4325,  1.0791,  ...,  0.4068, -0.2574, -0.1989]],\n",
              "\n",
              "        [[ 0.9140,  3.6093,  0.5437,  ...,  1.1365, -2.1639,  0.9462],\n",
              "         [ 0.5839,  2.9879,  0.3634,  ...,  0.5912, -1.6075,  0.1071],\n",
              "         [ 0.7473,  3.1147, -0.5953,  ...,  1.1040, -1.6608, -0.1471],\n",
              "         ...,\n",
              "         [ 0.4685,  2.7095, -0.1152,  ...,  0.7070, -1.8229,  0.3451],\n",
              "         [ 0.3734,  3.2925,  0.0284,  ...,  1.4541, -1.3113, -0.1811],\n",
              "         [ 0.9314,  2.3205,  0.9960,  ...,  0.3846, -0.2787, -0.2645]]],\n",
              "       device='cuda:0'), tensor([[[-1.6014,  0.9603, -0.0506,  ...,  0.5697, -0.9437,  0.2266],\n",
              "         [-1.2886,  2.4758,  1.5815,  ..., -0.3711, -1.2369,  1.0779],\n",
              "         [ 0.1049,  1.1608,  1.1385,  ...,  0.3784, -0.4943, -0.1275],\n",
              "         ...,\n",
              "         [ 0.0734,  0.3015,  0.8112,  ...,  0.4238, -0.8704,  0.4027],\n",
              "         [-1.1347,  0.1710,  0.6437,  ..., -0.3010, -0.9379, -0.6410],\n",
              "         [ 0.3154,  0.6963,  0.3411,  ..., -1.4456,  0.5106, -0.6756]],\n",
              "\n",
              "        [[-1.2551,  0.5207, -0.6333,  ..., -0.3341, -0.9999,  0.0188],\n",
              "         [-2.0354,  3.0436,  1.6392,  ..., -0.1072, -1.5391,  0.4428],\n",
              "         [-0.1955,  1.5332,  1.0997,  ...,  0.9514, -0.5078, -0.4271],\n",
              "         ...,\n",
              "         [ 1.0929,  0.4406,  0.6475,  ...,  1.0561, -1.0621,  0.0569],\n",
              "         [-1.5171,  0.4658,  0.9910,  ...,  0.7310, -1.0034, -1.2540],\n",
              "         [-0.2452,  0.6376,  0.5273,  ..., -1.2973, -0.4862, -0.2600]],\n",
              "\n",
              "        [[-1.3481,  1.3846,  0.2463,  ..., -0.1808, -1.5783,  0.5354],\n",
              "         [-0.5641,  3.8363,  1.1460,  ..., -0.8917, -1.1256,  0.2780],\n",
              "         [ 0.8205,  0.3388,  1.2592,  ...,  1.4066, -1.2857, -0.3310],\n",
              "         ...,\n",
              "         [ 1.0150,  0.4310,  1.1986,  ...,  1.0090, -1.1312, -0.4048],\n",
              "         [-1.4087,  1.2255,  0.6227,  ...,  0.4440, -0.7924, -1.8480],\n",
              "         [-0.8834,  1.2405, -0.5920,  ..., -0.1284, -0.1142, -0.6611]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.4948,  3.1209,  0.6952,  ...,  0.7950, -1.3878,  0.7721],\n",
              "         [-0.0807,  2.6918,  0.8848,  ...,  0.1132, -0.5661,  0.2204],\n",
              "         [ 0.3329,  2.9651, -0.1140,  ...,  0.5957, -0.8390, -0.3142],\n",
              "         ...,\n",
              "         [ 0.4209,  2.4078,  0.4508,  ...,  0.4336, -1.4297,  0.0560],\n",
              "         [-0.0193,  2.8925,  0.7675,  ...,  1.3215, -0.6946, -0.1497],\n",
              "         [ 0.6679,  2.2096,  0.9126,  ...,  0.4688,  0.4667,  0.1544]],\n",
              "\n",
              "        [[ 0.5412,  3.1011,  0.7400,  ...,  0.8977, -1.3286,  0.7683],\n",
              "         [-0.1522,  2.6682,  0.8225,  ..., -0.0431, -0.4979,  0.1189],\n",
              "         [ 0.3154,  2.9657, -0.1063,  ...,  0.6522, -0.7922, -0.2725],\n",
              "         ...,\n",
              "         [ 0.2226,  2.4168,  0.4646,  ...,  0.2342, -1.2561,  0.2497],\n",
              "         [ 0.0202,  2.8771,  0.5485,  ...,  1.3734, -0.5962, -0.1214],\n",
              "         [ 0.6695,  2.3209,  1.0176,  ...,  0.3982,  0.3938, -0.0102]],\n",
              "\n",
              "        [[ 0.6433,  3.0918,  0.7645,  ...,  1.0348, -1.2974,  0.7674],\n",
              "         [-0.2084,  2.5926,  0.7290,  ..., -0.0719, -0.5392,  0.1154],\n",
              "         [ 0.2652,  2.9574, -0.1618,  ...,  0.7089, -0.7404, -0.2567],\n",
              "         ...,\n",
              "         [ 0.1593,  2.3639,  0.4140,  ...,  0.1695, -1.1334,  0.2998],\n",
              "         [ 0.0334,  2.8914,  0.3907,  ...,  1.4053, -0.6098, -0.1255],\n",
              "         [ 0.6078,  2.2176,  1.0256,  ...,  0.4480,  0.4225, -0.0482]]],\n",
              "       device='cuda:0'), tensor([[[-2.2235e+00,  9.7192e-01, -5.7273e-01,  ...,  6.5344e-01,\n",
              "          -9.0424e-01,  2.4667e-01],\n",
              "         [-1.3993e+00,  2.5165e+00,  8.5230e-01,  ..., -8.2894e-01,\n",
              "          -5.6751e-01,  1.3602e+00],\n",
              "         [-5.6459e-01,  1.1035e+00,  9.6384e-01,  ...,  4.7863e-01,\n",
              "          -4.5886e-01, -2.1922e-01],\n",
              "         ...,\n",
              "         [-2.8522e-02,  4.6121e-01,  3.4711e-01,  ...,  3.2833e-01,\n",
              "          -1.0771e+00, -2.7124e-02],\n",
              "         [-8.8815e-01,  7.0181e-01,  3.3267e-01,  ..., -1.0926e-01,\n",
              "          -5.8163e-01,  1.2386e-01],\n",
              "         [ 3.2021e-01,  6.2463e-01,  5.3697e-01,  ..., -1.6963e+00,\n",
              "           6.3571e-02, -5.4266e-01]],\n",
              "\n",
              "        [[-1.8707e+00,  7.9332e-01, -1.0562e+00,  ..., -1.8317e-01,\n",
              "          -8.9720e-01, -3.1365e-01],\n",
              "         [-1.6995e+00,  2.9670e+00,  5.8239e-01,  ..., -5.6569e-01,\n",
              "          -9.7125e-01,  7.7986e-01],\n",
              "         [-5.2735e-01,  1.3249e+00,  8.3807e-01,  ...,  8.3364e-01,\n",
              "          -2.2737e-01, -6.2528e-01],\n",
              "         ...,\n",
              "         [ 1.1331e+00,  7.8704e-01,  6.0506e-02,  ...,  1.0139e+00,\n",
              "          -1.0098e+00, -5.8876e-01],\n",
              "         [-1.1781e+00,  8.7465e-01,  3.8237e-01,  ...,  6.9020e-01,\n",
              "          -2.7640e-01, -1.8120e-01],\n",
              "         [ 1.0204e-01,  4.4774e-01,  7.0605e-01,  ..., -1.5454e+00,\n",
              "          -6.7109e-01, -6.5188e-01]],\n",
              "\n",
              "        [[-1.9674e+00,  1.8647e+00, -1.6704e-02,  ..., -2.8525e-01,\n",
              "          -1.0507e+00, -3.7904e-02],\n",
              "         [-1.4978e-02,  3.8149e+00,  3.5584e-01,  ..., -9.8771e-01,\n",
              "          -6.9050e-01,  3.9414e-01],\n",
              "         [ 3.5970e-01,  1.4565e-01,  6.7637e-01,  ...,  1.3774e+00,\n",
              "          -1.0423e+00, -6.2090e-01],\n",
              "         ...,\n",
              "         [ 9.8678e-01,  7.5664e-01,  3.6229e-01,  ...,  8.6056e-01,\n",
              "          -1.0139e+00, -1.1777e+00],\n",
              "         [-9.9782e-01,  1.8601e+00, -5.6091e-02,  ...,  4.4998e-01,\n",
              "          -4.1721e-01, -1.5102e+00],\n",
              "         [-1.6398e+00,  1.2557e+00, -3.9924e-01,  ..., -1.6016e-01,\n",
              "           4.4766e-04, -4.8079e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 3.2855e-01,  2.3547e+00,  5.3169e-01,  ...,  9.5165e-01,\n",
              "          -1.4996e+00,  5.7124e-01],\n",
              "         [ 5.0158e-01,  2.4943e+00,  4.4457e-01,  ..., -6.8692e-02,\n",
              "          -1.4795e-01,  2.0909e-01],\n",
              "         [ 6.2581e-01,  2.7007e+00, -5.2664e-01,  ...,  1.0346e+00,\n",
              "          -1.0003e+00, -1.9963e-01],\n",
              "         ...,\n",
              "         [ 1.0623e+00,  1.8229e+00,  5.2502e-01,  ...,  4.6573e-01,\n",
              "          -1.0260e+00, -8.8072e-02],\n",
              "         [ 6.1347e-01,  2.5833e+00,  3.2863e-01,  ...,  1.2384e+00,\n",
              "          -3.2467e-01, -1.9617e-01],\n",
              "         [ 5.6583e-01,  2.0602e+00,  8.2659e-01,  ...,  5.2996e-01,\n",
              "          -4.8014e-03, -1.2912e-02]],\n",
              "\n",
              "        [[ 3.3460e-01,  2.3320e+00,  5.8984e-01,  ...,  1.0262e+00,\n",
              "          -1.4871e+00,  5.6492e-01],\n",
              "         [ 4.0798e-01,  2.4816e+00,  3.2150e-01,  ..., -1.3961e-01,\n",
              "          -2.3850e-02,  1.7828e-01],\n",
              "         [ 5.6562e-01,  2.7016e+00, -5.3057e-01,  ...,  1.0972e+00,\n",
              "          -9.5733e-01, -1.4561e-01],\n",
              "         ...,\n",
              "         [ 9.0261e-01,  1.7464e+00,  3.9015e-01,  ...,  2.4887e-01,\n",
              "          -9.1708e-01,  8.6670e-02],\n",
              "         [ 5.0423e-01,  2.4924e+00,  2.5814e-01,  ...,  1.3389e+00,\n",
              "          -2.6124e-01, -3.3499e-01],\n",
              "         [ 5.3993e-01,  2.2050e+00,  9.4522e-01,  ...,  4.9503e-01,\n",
              "           1.7898e-04, -9.8078e-02]],\n",
              "\n",
              "        [[ 4.1308e-01,  2.3342e+00,  6.2635e-01,  ...,  1.1720e+00,\n",
              "          -1.4984e+00,  5.5107e-01],\n",
              "         [ 3.0886e-01,  2.4492e+00,  1.7660e-01,  ..., -6.0352e-02,\n",
              "          -4.3776e-02,  2.3436e-01],\n",
              "         [ 5.1809e-01,  2.6658e+00, -6.0813e-01,  ...,  1.1678e+00,\n",
              "          -9.0795e-01, -1.2041e-01],\n",
              "         ...,\n",
              "         [ 9.1710e-01,  1.6286e+00,  2.9237e-01,  ...,  1.7220e-01,\n",
              "          -9.1906e-01,  1.0124e-01],\n",
              "         [ 4.9140e-01,  2.4172e+00,  1.3244e-01,  ...,  1.3927e+00,\n",
              "          -2.5338e-01, -3.7807e-01],\n",
              "         [ 4.4520e-01,  2.1219e+00,  9.6473e-01,  ...,  5.9439e-01,\n",
              "           6.3337e-02, -2.3043e-02]]], device='cuda:0'), tensor([[[-1.2067,  0.3691, -0.3635,  ...,  0.6308, -0.6641,  0.0416],\n",
              "         [-1.2674,  1.9263,  0.6067,  ..., -0.0951, -0.1972,  0.7553],\n",
              "         [-0.0435,  0.7661,  1.5695,  ..., -0.1018, -0.4297, -0.0734],\n",
              "         ...,\n",
              "         [ 0.4981,  0.0623,  0.8036,  ...,  0.4548, -0.3027,  0.2134],\n",
              "         [-0.8174, -0.2436,  0.4163,  ..., -0.3239, -0.2747,  0.8687],\n",
              "         [ 0.7131,  0.0353,  0.8596,  ..., -0.8240, -0.0620, -0.4728]],\n",
              "\n",
              "        [[-0.6383,  0.2210, -0.4863,  ..., -0.5307, -0.6236, -0.2510],\n",
              "         [-1.6164,  2.3455,  0.3605,  ...,  0.1441, -0.5135,  0.4149],\n",
              "         [-0.4311,  1.2881,  1.2499,  ...,  0.2051, -0.0445, -0.5868],\n",
              "         ...,\n",
              "         [ 1.5046,  0.2900,  0.5298,  ...,  0.8078, -0.3685, -0.2849],\n",
              "         [-0.9572, -0.0060,  0.4773,  ...,  0.0685, -0.1416,  0.6464],\n",
              "         [ 0.7332, -0.4040,  0.7399,  ..., -0.8887, -0.4614, -0.1488]],\n",
              "\n",
              "        [[-0.9603,  0.9885,  0.4549,  ..., -0.5667, -0.9261,  0.2501],\n",
              "         [-0.4269,  2.9472,  0.1231,  ..., -0.2734, -0.3177,  0.2801],\n",
              "         [ 0.3989,  0.1850,  1.1900,  ...,  0.6768, -0.2933, -0.3701],\n",
              "         ...,\n",
              "         [ 1.2303,  0.2586,  0.6084,  ...,  0.7164, -0.2747, -0.6187],\n",
              "         [-0.8065,  0.9440,  0.0713,  ..., -0.0945, -0.2393, -0.2525],\n",
              "         [-0.9346,  0.4101, -0.2831,  ..., -0.2937,  0.1050,  0.0109]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.3415,  1.8670,  0.3557,  ...,  0.4049, -1.2422, -0.1664],\n",
              "         [ 0.8889,  1.3904, -0.0267,  ..., -0.3531, -0.1885, -0.2895],\n",
              "         [ 1.0995,  1.9114, -0.2546,  ...,  0.2313, -0.9688, -0.7851],\n",
              "         ...,\n",
              "         [ 1.4111,  1.2367,  0.6878,  ..., -0.4671, -0.8253, -0.5422],\n",
              "         [ 1.5199,  1.3680,  0.4159,  ...,  0.0501, -0.5179, -0.3747],\n",
              "         [ 1.2567,  0.7433,  0.9717,  ..., -0.2827, -0.2788, -0.3948]],\n",
              "\n",
              "        [[ 0.2944,  1.8691,  0.3598,  ...,  0.4445, -1.2704, -0.1490],\n",
              "         [ 0.8695,  1.4247, -0.1200,  ..., -0.3644, -0.1019, -0.3243],\n",
              "         [ 1.0813,  1.9241, -0.2452,  ...,  0.2581, -0.9251, -0.7276],\n",
              "         ...,\n",
              "         [ 1.2859,  1.1301,  0.5951,  ..., -0.6477, -0.7379, -0.4033],\n",
              "         [ 1.2985,  1.3412,  0.2742,  ...,  0.1755, -0.4977, -0.5135],\n",
              "         [ 1.2481,  0.9220,  1.1174,  ..., -0.2715, -0.3843, -0.5708]],\n",
              "\n",
              "        [[ 0.3655,  1.8772,  0.3270,  ...,  0.5551, -1.3073, -0.1716],\n",
              "         [ 0.7582,  1.4251, -0.2041,  ..., -0.3305, -0.1418, -0.3013],\n",
              "         [ 1.0824,  1.9170, -0.3039,  ...,  0.2940, -0.8627, -0.7097],\n",
              "         ...,\n",
              "         [ 1.3021,  0.9965,  0.4897,  ..., -0.6641, -0.7888, -0.3333],\n",
              "         [ 1.2514,  1.2913,  0.1140,  ...,  0.2089, -0.5156, -0.6016],\n",
              "         [ 1.2210,  0.9511,  1.1541,  ..., -0.1694, -0.3766, -0.5622]]],\n",
              "       device='cuda:0'), tensor([[[-1.0411,  0.6274, -0.3186,  ...,  0.5600, -0.7148,  0.3412],\n",
              "         [-1.8879,  1.3051,  0.1976,  ...,  0.1463, -0.6501,  1.0067],\n",
              "         [-0.3558,  0.9384,  2.2446,  ...,  0.5630, -1.0721,  0.1606],\n",
              "         ...,\n",
              "         [ 0.3424,  0.0603,  0.6179,  ...,  0.9088, -0.0732, -0.5099],\n",
              "         [-1.3695, -0.8506, -0.1168,  ..., -0.1654,  0.4725, -0.0585],\n",
              "         [ 0.0499, -0.0581,  0.5056,  ..., -0.6643,  0.3795, -0.9650]],\n",
              "\n",
              "        [[-0.3827,  0.3729, -0.5706,  ..., -0.9400, -0.4773,  0.1275],\n",
              "         [-1.9061,  2.0091, -0.0553,  ...,  0.4391, -1.1967,  0.6347],\n",
              "         [-0.4127,  1.4589,  1.8291,  ...,  0.6261,  0.0232, -0.1960],\n",
              "         ...,\n",
              "         [ 1.5335,  0.5227,  0.0788,  ...,  1.3067, -0.3115, -0.6600],\n",
              "         [-1.2506, -0.4141, -0.0421,  ...,  0.0879,  0.4508,  0.1644],\n",
              "         [ 0.5489, -0.8370,  0.2160,  ..., -1.1228,  0.2008, -0.6094]],\n",
              "\n",
              "        [[-1.2877,  1.0831,  0.3191,  ..., -1.0762, -0.9282,  0.3032],\n",
              "         [-0.6287,  2.8613, -0.3472,  ..., -0.2969, -0.5641,  0.4259],\n",
              "         [-0.1966, -0.0483,  2.1824,  ...,  1.0820, -0.4956, -0.1214],\n",
              "         ...,\n",
              "         [ 1.0974,  0.4331,  0.3681,  ...,  0.7945, -0.1858, -0.9351],\n",
              "         [-1.1084,  0.5182, -0.2709,  ..., -0.2910,  0.2508, -0.4484],\n",
              "         [-0.8867,  0.0679, -0.0036,  ..., -0.0924, -0.4226, -0.2292]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.4840,  1.8664,  0.9588,  ...,  0.0938, -0.7874,  0.2597],\n",
              "         [ 0.8926,  1.4416, -0.4337,  ..., -0.1895, -0.3765,  0.8263],\n",
              "         [ 1.5713,  2.3797, -0.2239,  ..., -0.1750, -0.9163, -0.0206],\n",
              "         ...,\n",
              "         [ 1.4621,  1.7641,  0.4787,  ..., -0.3798, -0.6527,  0.2526],\n",
              "         [ 2.4472,  1.6343,  0.1423,  ...,  0.4688,  0.0845,  0.0488],\n",
              "         [ 1.3196,  1.6119,  0.8112,  ...,  0.3986,  0.0676,  0.7718]],\n",
              "\n",
              "        [[ 0.4187,  1.8630,  0.9090,  ...,  0.0919, -0.7579,  0.2794],\n",
              "         [ 0.9194,  1.4706, -0.5259,  ..., -0.0653, -0.3363,  0.7676],\n",
              "         [ 1.5650,  2.3988, -0.1837,  ..., -0.1505, -0.8710,  0.0073],\n",
              "         ...,\n",
              "         [ 1.3809,  1.6499,  0.4957,  ..., -0.5290, -0.5571,  0.3433],\n",
              "         [ 2.3212,  1.4913, -0.0124,  ...,  0.4158,  0.0177,  0.0481],\n",
              "         [ 1.3066,  1.7639,  0.8979,  ...,  0.4056, -0.1001,  0.5453]],\n",
              "\n",
              "        [[ 0.4798,  1.8780,  0.8239,  ...,  0.1600, -0.7521,  0.2896],\n",
              "         [ 0.8592,  1.4494, -0.6066,  ...,  0.0203, -0.3959,  0.7937],\n",
              "         [ 1.5505,  2.4059, -0.2450,  ..., -0.1092, -0.7859,  0.0045],\n",
              "         ...,\n",
              "         [ 1.4453,  1.5512,  0.5000,  ..., -0.5491, -0.5984,  0.4447],\n",
              "         [ 2.2798,  1.4304, -0.1494,  ...,  0.3805,  0.0290, -0.0244],\n",
              "         [ 1.3303,  1.7157,  0.9767,  ...,  0.4547, -0.1808,  0.4851]]],\n",
              "       device='cuda:0'), tensor([[[-1.6908e-01, -3.2129e-01, -3.9907e-01,  ...,  3.5022e-01,\n",
              "          -8.7454e-01,  6.7142e-01],\n",
              "         [-6.2202e-01, -1.5570e-01,  5.0320e-01,  ...,  7.0034e-01,\n",
              "           5.9249e-02,  1.9011e+00],\n",
              "         [-6.9612e-01, -1.2298e-01,  1.0033e+00,  ...,  1.5765e+00,\n",
              "          -2.1831e-01,  1.1775e+00],\n",
              "         ...,\n",
              "         [ 7.6213e-02, -1.1596e+00,  4.0688e-01,  ...,  1.5847e+00,\n",
              "           4.7949e-01, -2.1286e-01],\n",
              "         [-7.0477e-01, -1.5253e+00, -6.1061e-01,  ...,  4.4126e-01,\n",
              "          -1.0739e-01,  3.1762e-02],\n",
              "         [ 1.5605e-01, -1.1184e+00,  6.8711e-01,  ..., -5.0270e-01,\n",
              "           2.6280e-01, -4.9850e-01]],\n",
              "\n",
              "        [[ 3.2763e-01, -4.5598e-01, -5.6302e-01,  ..., -6.3487e-01,\n",
              "          -2.1077e-02,  5.2679e-01],\n",
              "         [-6.2171e-01,  2.7139e-01,  1.6418e-01,  ...,  7.2776e-01,\n",
              "          -2.8521e-01,  1.4276e+00],\n",
              "         [-7.1494e-01,  3.4475e-01,  8.8302e-01,  ...,  9.0072e-01,\n",
              "           2.4065e-01,  9.2313e-01],\n",
              "         ...,\n",
              "         [ 9.7846e-01, -7.6043e-01,  2.1172e-01,  ...,  1.5132e+00,\n",
              "           2.2928e-01, -4.2205e-01],\n",
              "         [-6.0441e-01, -1.1505e+00, -4.8036e-01,  ...,  4.6432e-01,\n",
              "          -1.2443e-03,  3.3656e-01],\n",
              "         [ 1.9699e-01, -1.5426e+00,  5.3741e-01,  ..., -6.1842e-01,\n",
              "           4.4033e-01, -3.3037e-01]],\n",
              "\n",
              "        [[-5.5614e-01,  3.6284e-01, -2.8739e-01,  ..., -5.4735e-01,\n",
              "          -4.3463e-01,  7.3936e-01],\n",
              "         [-1.1134e-01,  1.4556e+00, -7.5065e-02,  ...,  3.3502e-01,\n",
              "           9.1724e-02,  1.2860e+00],\n",
              "         [-4.6628e-01, -1.1473e+00,  1.1123e+00,  ...,  1.5290e+00,\n",
              "          -6.8775e-02,  9.4040e-01],\n",
              "         ...,\n",
              "         [ 6.5629e-01, -7.0827e-01,  7.5873e-01,  ...,  1.1967e+00,\n",
              "           1.2621e-01, -6.2715e-01],\n",
              "         [-5.0243e-01, -3.4234e-01, -6.0155e-01,  ...,  1.1175e-01,\n",
              "          -3.0385e-01,  6.0565e-02],\n",
              "         [-5.6455e-01, -1.0054e+00,  2.3523e-01,  ...,  4.1327e-02,\n",
              "           1.0445e-01,  7.2502e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 5.0074e-01,  1.5840e+00,  1.0919e-01,  ...,  1.8268e-01,\n",
              "          -3.7248e-01,  5.6049e-01],\n",
              "         [ 5.8786e-01,  6.8963e-01, -3.6213e-01,  ...,  4.1248e-01,\n",
              "           5.8839e-03,  1.9277e+00],\n",
              "         [ 5.1119e-01,  1.0390e+00, -3.7754e-01,  ...,  5.0214e-01,\n",
              "          -1.2013e+00,  2.6051e-01],\n",
              "         ...,\n",
              "         [ 8.6646e-01,  1.6466e+00, -7.5607e-02,  ...,  3.4560e-01,\n",
              "          -1.5769e-01,  9.7354e-01],\n",
              "         [ 1.5328e+00,  1.4719e+00,  2.0082e-01,  ...,  8.1908e-01,\n",
              "           6.9391e-01,  9.4011e-01],\n",
              "         [ 1.0713e+00,  6.1101e-01,  5.6175e-01,  ...,  5.9341e-01,\n",
              "           5.3984e-01,  1.4866e+00]],\n",
              "\n",
              "        [[ 4.8479e-01,  1.6515e+00,  1.3159e-01,  ...,  1.5900e-01,\n",
              "          -3.7620e-01,  5.3324e-01],\n",
              "         [ 5.4982e-01,  7.5588e-01, -3.6578e-01,  ...,  5.4140e-01,\n",
              "          -4.5863e-03,  1.8378e+00],\n",
              "         [ 4.8786e-01,  1.0782e+00, -3.7436e-01,  ...,  5.2619e-01,\n",
              "          -1.1719e+00,  2.8083e-01],\n",
              "         ...,\n",
              "         [ 7.8618e-01,  1.5857e+00, -7.3262e-02,  ...,  2.5246e-01,\n",
              "          -1.0219e-01,  9.2199e-01],\n",
              "         [ 1.4017e+00,  1.5470e+00,  1.8581e-01,  ...,  7.4809e-01,\n",
              "           6.5989e-01,  9.5298e-01],\n",
              "         [ 1.0345e+00,  6.1333e-01,  7.1680e-01,  ...,  7.0531e-01,\n",
              "           4.6727e-01,  1.2509e+00]],\n",
              "\n",
              "        [[ 5.3660e-01,  1.7034e+00,  1.0016e-01,  ...,  1.9020e-01,\n",
              "          -3.8042e-01,  4.6944e-01],\n",
              "         [ 4.3991e-01,  7.5422e-01, -3.7553e-01,  ...,  6.0961e-01,\n",
              "          -5.5980e-02,  1.7960e+00],\n",
              "         [ 4.8317e-01,  1.0919e+00, -4.3998e-01,  ...,  5.6625e-01,\n",
              "          -1.1009e+00,  2.7552e-01],\n",
              "         ...,\n",
              "         [ 7.8250e-01,  1.4363e+00, -3.2302e-02,  ...,  2.2724e-01,\n",
              "          -1.6976e-01,  9.0540e-01],\n",
              "         [ 1.3663e+00,  1.5399e+00,  1.2369e-01,  ...,  7.1062e-01,\n",
              "           6.3344e-01,  9.0415e-01],\n",
              "         [ 1.0585e+00,  5.5598e-01,  8.1041e-01,  ...,  8.1166e-01,\n",
              "           4.3459e-01,  1.1549e+00]]], device='cuda:0')), hidden_states=None, attentions=None)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs = model(input_ids.reshape(-1,512), token_type_ids=None, attention_mask=attention_mask, labels=targets)\n",
        "outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l1sYAnBYJtk",
        "outputId": "167d6da0-8d98-486b-e783-fac3ff76b23b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(outputs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGbUFkoDYJq7"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "def train_epoch(model, data_loader, optimizer, device, scheduler, n_examples):\n",
        "    model = model.train()\n",
        "    losses = []\n",
        "    acc = 0\n",
        "    counter = 0\n",
        "  \n",
        "    for d in data_loader:\n",
        "        input_ids = d[\"input_ids\"].reshape(-1,512).to(device)\n",
        "        attention_mask = d[\"attention_mask\"].to(device)\n",
        "        targets = d[\"targets\"].to(device)\n",
        "        \n",
        "        outputs = model(input_ids=input_ids, token_type_ids=None, attention_mask=attention_mask, labels = targets)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "\n",
        "        # preds = preds.cpu().detach().numpy()\n",
        "        _, prediction = torch.max(outputs[1], dim=1)\n",
        "        targets = targets.cpu().detach().numpy()\n",
        "        prediction = prediction.cpu().detach().numpy()\n",
        "        accuracy = metrics.accuracy_score(targets, prediction)\n",
        "\n",
        "        acc += accuracy\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        loss.backward()\n",
        "\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        counter = counter + 1\n",
        "\n",
        "    return acc / counter, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pubeRiroYJoW"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, device, n_examples):\n",
        "    model = model.eval()\n",
        "    losses = []\n",
        "    acc = 0\n",
        "    counter = 0\n",
        "  \n",
        "    with torch.no_grad():\n",
        "        for d in data_loader:\n",
        "            input_ids = d[\"input_ids\"].reshape(-1,512).to(device)\n",
        "            attention_mask = d[\"attention_mask\"].to(device)\n",
        "            targets = d[\"targets\"].to(device)\n",
        "            \n",
        "            outputs = model(input_ids=input_ids, token_type_ids=None, attention_mask=attention_mask, labels = targets)\n",
        "            loss = outputs[0]\n",
        "            logits = outputs[1]\n",
        "\n",
        "            _, prediction = torch.max(outputs[1], dim=1)\n",
        "            targets = targets.cpu().detach().numpy()\n",
        "            prediction = prediction.cpu().detach().numpy()\n",
        "            accuracy = metrics.accuracy_score(targets, prediction)\n",
        "\n",
        "            acc += accuracy\n",
        "            losses.append(loss.item())\n",
        "            counter += 1\n",
        "\n",
        "    return acc / counter, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42lektzOYJl8",
        "outputId": "e15ba0ef-fb56-42ed-a8b7-2534c4ac2c5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Train loss 0.4858877947147345 Train accuracy 0.7707667731629393\n",
            "Val loss 0.3478690733776448 Val accuracy 0.8865248226950354\n",
            "\n",
            "Epoch 2/4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Train loss 0.28269685469632244 Train accuracy 0.9230564430244942\n",
            "Val loss 0.4818905067676761 Val accuracy 0.9011524822695035\n",
            "\n",
            "Epoch 3/4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Train loss 0.18843202872026496 Train accuracy 0.9543397231096912\n",
            "Val loss 0.3952102256782047 Val accuracy 0.9171099290780141\n",
            "\n",
            "Epoch 4/4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Train loss 0.13947084306278568 Train accuracy 0.9688498402555911\n",
            "Val loss 0.4406345460069752 Val accuracy 0.9206560283687943\n",
            "\n",
            "CPU times: user 1h 46min 52s, sys: 53.2 s, total: 1h 47min 45s\n",
            "Wall time: 1h 48min 17s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "    print('-' * 100)\n",
        "\n",
        "    train_acc, train_loss = train_epoch(\n",
        "        model,\n",
        "        train_data_loader,     \n",
        "        optimizer, \n",
        "        device, \n",
        "        scheduler, \n",
        "        len(df_train)\n",
        "    )\n",
        "\n",
        "    print(f'Train loss {train_loss} Train accuracy {train_acc}')\n",
        "\n",
        "    val_acc, val_loss = eval_model(\n",
        "        model,\n",
        "        val_data_loader, \n",
        "        device, \n",
        "        len(df_val)\n",
        "    )\n",
        "\n",
        "    print(f'Val loss {val_loss} Val accuracy {val_acc}')\n",
        "    print()\n",
        "\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "\n",
        "    if val_acc > best_accuracy:\n",
        "        torch.save(model.state_dict(), '/content/drive/MyDrive/XLNET_MODELDATA/XlNet_Model.bin')\n",
        "        best_accuracy = val_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7u_gzt9YJjC",
        "outputId": "8785a39c-b1cf-4bd6-b56b-08e4fb253add"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/XLNET_MODELDATA/XlNet_Model_1.bin'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgSXvMhXYJgb"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_m74czhYJdl",
        "outputId": "0efbd247-70df-485d-b93b-d4ecea340541"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy : 0.9659090909090909\n",
            "Test Loss : 0.2567585254234345\n"
          ]
        }
      ],
      "source": [
        "test_acc, test_loss = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "print('Test Accuracy :', test_acc)\n",
        "print('Test Loss :', test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7w1a9AcXwU7"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, data_loader):\n",
        "    model = model.eval()\n",
        "    \n",
        "    sentiment_texts = []\n",
        "    predictions = []\n",
        "    prediction_probs = []\n",
        "    real_values = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for d in data_loader:\n",
        "\n",
        "            texts = d[\"sentiment_text\"]\n",
        "            input_ids = d[\"input_ids\"].reshape(-1,512).to(device)\n",
        "            attention_mask = d[\"attention_mask\"].to(device)\n",
        "            targets = d[\"targets\"].to(device)\n",
        "            \n",
        "            outputs = model(input_ids=input_ids, token_type_ids=None, attention_mask=attention_mask, labels = targets)\n",
        "\n",
        "            loss = outputs[0]\n",
        "            logits = outputs[1]\n",
        "            \n",
        "            _, preds = torch.max(outputs[1], dim=1)\n",
        "\n",
        "            probs = F.softmax(outputs[1], dim=1)\n",
        "\n",
        "            sentiment_texts.extend(texts)\n",
        "            predictions.extend(preds)\n",
        "            prediction_probs.extend(probs)\n",
        "            real_values.extend(targets)\n",
        "\n",
        "    predictions = torch.stack(predictions).cpu()\n",
        "    prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "    real_values = torch.stack(real_values).cpu()\n",
        "    return sentiment_texts, predictions, prediction_probs, real_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWFPwZgktaUH"
      },
      "outputs": [],
      "source": [
        "y_sentiment_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH_gsgaptaRg",
        "outputId": "6638a7fd-2c7c-4984-f58b-fe24a8312317"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.97      0.96      0.97       491\n",
            "    negative       0.96      0.97      0.97       475\n",
            "\n",
            "    accuracy                           0.97       966\n",
            "   macro avg       0.97      0.97      0.97       966\n",
            "weighted avg       0.97      0.97      0.97       966\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIas2765taOb"
      },
      "outputs": [],
      "source": []
    }
  ]
}